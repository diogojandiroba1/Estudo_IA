{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMnnx/UMXRARfPOI5Cj+Xr+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6L-Tupu3qcjs"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"code","source":["MODEL_CONFIG = \"MobileNetSSD_deploy.prototxt\"\n","MODEL_WEIGHTS = \"MobileNetSSD_deploy.caffemodel\"\n","CLASSES = [\"background\",\"aeroplane\",\"bicycle\",\"bird\",\"boat\", \"bottle\", \"bus\",\n","           \"car\", \"cat\", \"chair\", \"cow\", \"dinigtable\", \"dog\", \"horse\", \"motorbike\", \"person\",\n","           \"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\"]"],"metadata":{"id":"lJ14LAX_BvcL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net = cv2.dnn.readNetFromCaffe(MODEL_CONFIG,MODEL_WEIGHTS)"],"metadata":{"id":"_hAiZfYCEW1s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def detect_person_in_video(video_path):\n","  cap = cv2.VideoCapture(video_path)\n","  frame_count = 0\n","  while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","      print(\"Fim do vídeo ou erro de leitura\")\n","      break\n","    frame_count += 1\n","    (h,w) = frame.shape[:2]\n","    blob = cv2.dnn.blobFromImage(frame, 0.007843, (300,300), 127.5)\n","    net.setInput(blob)\n","    detections = net.forward()\n","\n","    for i in range(detections.shape[2]):\n","      confidence = detections[0,0,i,2]\n","      if confidence > 0.5:\n","        idx = int(detections[0,0,i,1])\n","        if CLASSES[idx] == \"person\":\n","          box = detections[0,0,i,3:7] * np.array([w,h,w,h])\n","          (startX, startY, endX, endY) = box.astype(\"int\")\n","\n","          label  = f\"{CLASSES[idx]}: {confidence * 100:.2f}%\"\n","          cv2.rectangle(frame, (startX,startY),(endX, endY),(0,255,0),2)\n","          cv2.putText(frame, label, (startX, startY-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0,255,0),2)\n","          print(f\"Pessoa Detectada no Frame {frame_count}\")\n","          cv2_imshow(frame)\n","\n","          detected_frame_path = f\"detected_frame_{frame_count}.jpg\"\n","          cv2.imwrite(detected_frame_path, frame)\n","          print(f\"Frame salvo como {detected_frame_path}\")\n","\n","          cap.release()\n","          return \"Pessoa detectada no vídeo\"\n","  cap.release()\n","  return \"Nenhuma pessoa detectada no vídeo\"\n"],"metadata":{"id":"SiwQImmFEjGM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(detect_person_in_video(\"nopeople.mp4\"))"],"metadata":{"id":"qBiyCmZmMm10"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JNi020GpMxq9"},"execution_count":null,"outputs":[]}]}